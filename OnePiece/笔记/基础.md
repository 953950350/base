# 基础

## 什么是数据结构与算法

广义上来讲，数据结构就是指一组数据的存储结构，算法就是操作数据的一组方法。

数据结构为算法服务，算法也要作用在特定的数据结构之上。

如：数组具有随机访问的特点，常用的二分查找算法需要用数据来存储数据。但如果我们选择链表，二分查找就无法工作了，因为链表不支持随机访问。

## 复杂度分析

一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法。

### 大O复杂度表示法

```
T(n) = O(f(n))
```

代码执行时间随数据规模增长的变化趋势，也叫渐进时间复杂度，简称时间复杂度。公式中低阶、常量和系数对增长趋势影响都不是很大，所以都可以忽略，时间复杂度只需要关注最大量级即可。

### 时间复杂度分析

1. 只关注循环执行次数最多的一段代码

由于公式中的常量、低阶、系数等都会被忽略掉，所以我们只需要看最大阶的量级即可。我们在分析一个算法、一段代码的时间复杂度的时候，只需要关注循环执行最多的那一段代码。

2. 加法法则：总复杂度等于量级最大的那段代码的复杂度

总的时间复杂度等于量级最大的那段代码的时间复杂度：

如果T1(n)=O(f(n)), T2(n)=O(g(n)); 那么T(n)=T1(n)+T2(n)=max(O(fn), O(g(n)))=O(max(f(n),g(n))).

3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积


### 几种常见时间复杂度实例分析

常见的复杂度量级主要分为两类：多项式量级和非多项式量级。其中非多项式量级只有两个O(2^n)和O(n!)

当数据规模n越来越大时，非多项式量级执行事件会急剧增加，所以非多项式量级的算法是非常低效的算法。

#### 多项式时间复杂度

1. O(1)

只要代码的执行时间不随着n的增大而增大，这样的代码时间复杂度就是O(1)。

2. O(logn)、O(nlogn)

如：

```js
var i = 1
while(i <= n) {
    i = i * 2
}
```

i 从一开始取值，每次循环乘以2，当大于n时，循环结束。要想知道循环了多少次通过`2^x = n`可以得出`x = O(logn)`

O(nlogn)算法就是一段代码时间复杂度是O(logn)，我们循环执行n遍，时间复杂度就是O(nlogn)，O(nlogn)常见算法有：归并排序、快速排序。

3. O(m + n)、O(m * n)

代码复杂度由两个数据规模决定如：

```C++
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }
 
  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }
 
  return sum_1 + sum_2;
}
```

由于我们无法知道m和n的量级那个大，所以不能简单的利用加法法则省略掉另外一个，所以上面的代码时间复杂度就是O(m + n)。

### 空间复杂度分析

空间复杂度全称是渐进式空间复杂度，表示算法的存储空间和数据规模之间的增长关系。

```c++
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }
 
  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```

如上面这段代码中，在第三行申请了一个大小为n的数组，剩下代码都没有占用多少空间，所以整段代码的空间复杂度就是O(n)。

我们常见的空间复杂度就是O(1)、O(n)、O(n^2)。

### 最好、最坏情况时间复杂度

例如：

```c++
// n表示数组array的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```

上面这段代码，在数组中查找一个数出现的位置，根据不同情况，时间复杂度是不同的，如果这个数就在第一位，那么只需要遍历一次，时间复杂度就是O(1)，如果数组中不存在变量x，我们就需要把整个数组都遍历一遍，时间复杂度就是O(n)，所以不同情况下代码时间复杂度是不同的。

为了表示不同情况下不同的时间复杂度，我们引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。

最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。

最坏情况时间复杂度就是，在最坏情况下，执行这段代码的时间复杂度。

#### 平均情况时间复杂度

最好与最坏情况时间复杂度对应的都是最极端的情况下代码的复杂度，发生的概率并不大。为了更好的表示平均情况下的复杂度，我们需要引入另外一个概念：平均情况时间复杂度。

以上面查找变量的例子来看，要查找变量x在数组中的位置，有n + 1中情况，在数组的0~n-1位置上或者不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以n+1，就可以得到需要遍历的元素个数的平均值

#### 均摊时间复杂度

```c++
 // array表示一个长度为n的数组
 // 代码中的array.length就等于n
 int[] array = new int[n];
 int count = 0;
 
 void insert(int val) {
    if (count == array.length) {
       int sum = 0;
       for (int i = 0; i < array.length; ++i) {
          sum = sum + array[i];
       }
       array[0] = sum;
       count = 1;
    }

    array[count] = val;
    ++count;
 }
```

这段代码在大部分时间都是O(1)的复杂度，但是在数组值满了之后会有一次O(n)的事件复杂度操作，这种情况下将复杂度高的那次操作均摊到那些复杂度底的操作中，就是均摊时间复杂度，均摊之后的时间复杂度还是O(1)。